# Groq Chat ğŸš€ğŸ’¬

Groq Chat is a lightning-fast, browser-based chat interface for language models powered by Groq's LPU (Language Processing Unit). Experience ChatGPT-like conversations using Meta's LLAMA 3.1 series, with enhanced privacy and productivity features.

## ğŸŒŸ Features

- ğŸ§  Powered by Groq's LPU for ultra-fast language model inference
- ğŸ¤– Access to Meta's LLAMA 3.1 series models (405B, 70B, 8B parameters)
- ğŸ”’ Privacy-focused: Runs entirely in your browser, no server-side data storage
- ğŸŒ RAG support for web page URLs: Attach and crawl web pages for context-aware conversations
- ğŸ™ï¸ Speech-to-text functionality for voice interactions
- ğŸ“ Edit messages and branch conversations
- ğŸ’¾ Save and manage conversation history locally
- ğŸ—‘ï¸ Delete conversations as needed
- ğŸ”— No login required - just bring your Groq API key

## ğŸš€ Getting Started

### Online Version

Visit [https://groqchat-three.vercel.app/](https://groqchat-three.vercel.app/) to use Groq Chat online.

### Local Setup

To run Groq Chat locally:

1. Clone the repository:
   ```
   git clone https://github.com/yourusername/groq-chat.git
   cd groq-chat
   ```

2. Install dependencies:
   ```
   npm install
   ```

3. Run the development server:
   ```
   npm run dev
   ```

4. Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ”§ Usage

1. Enter your Groq API key when prompted.
2. Start chatting with the language model of your choice.
3. Use the URL attachment feature to add context from web pages.
4. Utilize speech-to-text for voice interactions.
5. Edit, branch, save, or delete conversations as needed.

## ğŸ› ï¸ Tech Stack

- Next.js
- Vercel for deployment
- IndexedDB for local storage
- Groq API for language model inference

## ğŸ”œ Upcoming Features

- Multi-modality support (when available from Groq)
- Custom JavaScript macros for enhanced functionality
- File attachment support (PDF, documents)
- Auto-formatting options

## ğŸ¤ Contributing

This is an open-source project. Contributions, issues, and feature requests are welcome!

## ğŸ“„ License

[MIT License](LICENSE)

## ğŸ™ Acknowledgements

- Groq for their incredible LPU technology
- Meta for the LLAMA 3.1 series models
- Vercel for their excellent hosting and deployment services

---

Built with â¤ï¸ by Unclecode (Follow me on [X](https://x.com/unclecode)).